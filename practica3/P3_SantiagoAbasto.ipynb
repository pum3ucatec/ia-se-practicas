{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. Contar el número de palabras en un texto simple\n"
      ],
      "metadata": {
        "id": "M9WFrD91KLPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "texto = \"Este es un ejemplo simple de texto para contar palabras.\"\n",
        "palabras = texto.split()\n",
        "print(f'Número de palabras: {len(palabras)}')\n"
      ],
      "metadata": {
        "id": "95lLjvE0KMPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Manipular cadenas: convertir texto a minúsculas y eliminar signos de puntuación\n"
      ],
      "metadata": {
        "id": "59001s5YKN5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "texto = \"Hola! ¿Cómo estás? Este es un ejemplo de texto.\"\n",
        "texto = texto.lower()  # Convertir a minúsculas\n",
        "texto = texto.translate(str.maketrans('', '', string.punctuation))  # Eliminar puntuación\n",
        "print(texto)\n"
      ],
      "metadata": {
        "id": "G0s9mFatKQFg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Usar listas y diccionarios para contar frecuencias de palabras\n"
      ],
      "metadata": {
        "id": "JvzuLsBuKSDD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "texto = \"manzana manzana pera manzana naranja pera\"\n",
        "palabras = texto.split()\n",
        "frecuencia = Counter(palabras)\n",
        "print(frecuencia)\n"
      ],
      "metadata": {
        "id": "dBvbPB7hKUtL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Instalar NLTK y descargar recursos\n",
        "\n"
      ],
      "metadata": {
        "id": "vKbEGqcbKWL3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "id": "cK-kuNFzKYDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Tokenización básica usando nltk.word_tokenize\n"
      ],
      "metadata": {
        "id": "ad3P4TvwKZQg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "texto = \"Natural Language Processing is fun!\"\n",
        "tokens = word_tokenize(texto)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "id": "yjkCDdOpKbw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Leer un corpus desde nltk.gutenberg"
      ],
      "metadata": {
        "id": "xSOolo_BKdEK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import gutenberg\n",
        "\n",
        "texto = gutenberg.raw('austen-emma.txt')\n",
        "print(texto[:500])  # Muestra las primeras 500 letras\n"
      ],
      "metadata": {
        "id": "LrGBd4O_KhYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Contar palabras únicas y su frecuencia en un corpus"
      ],
      "metadata": {
        "id": "3ePeCS43KiyO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokens = word_tokenize(texto)\n",
        "conteo = Counter(tokens)\n",
        "print(conteo.most_common(10))  # Top 10 palabras más frecuentes\n"
      ],
      "metadata": {
        "id": "DMSSeEioKk_B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Tokenización avanzada con expresiones regulares"
      ],
      "metadata": {
        "id": "JGuiCbPwKnYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from nltk.tokenize import regexp_tokenize\n",
        "\n",
        "texto = \"The price of oil is $123.45 today. U.S.A. stocks fell by 5%...\"\n",
        "pattern = r'''(?x)\n",
        "              (?:[A-Z]\\.)+         # Abreviaciones como U.S.A.\n",
        "              | \\$?\\d+(?:\\.\\d+)?%? # Monedas y porcentajes\n",
        "              | \\w+(?:-\\w+)*       # Palabras con guiones\n",
        "              | \\.\\.\\.             # Elipsis\n",
        "              | [][.,;\"'?():-_`]   # Otros tokens individuales\n",
        "            '''\n",
        "tokens = regexp_tokenize(texto, pattern)\n",
        "print(tokens)\n"
      ],
      "metadata": {
        "id": "Or1B2DuoKq-_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. Eliminar stopwords"
      ],
      "metadata": {
        "id": "NqJiO6kcKsU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tokens_limpios = [word for word in tokens if word.lower() not in stop_words]\n",
        "print(tokens_limpios)\n"
      ],
      "metadata": {
        "id": "WdbXKTDBKuM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. Visualización de frecuencias de palabras\n"
      ],
      "metadata": {
        "id": "FsaizavPKv24"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "frecuencias = Counter(tokens_limpios)\n",
        "palabras, valores = zip(*frecuencias.most_common(10))\n",
        "\n",
        "plt.bar(palabras, valores)\n",
        "plt.title(\"Top 10 palabras más comunes\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jblrzl-UKxu2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. Buscar patrones de palabras en contexto"
      ],
      "metadata": {
        "id": "kA9i46lkKzDx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.text import Text\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "text = Text(word_tokenize(texto))\n",
        "text.concordance(\"love\")  # Busca palabras con \"love\"\n"
      ],
      "metadata": {
        "id": "R7oWouKNK07J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. Stemming\n"
      ],
      "metadata": {
        "id": "gFwucJoLK4Zd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "print(stemmer.stem(\"running\"))  # Resultado: run\n"
      ],
      "metadata": {
        "id": "UlBRJ86nK5O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. Lematización (opcional)"
      ],
      "metadata": {
        "id": "8jH8OIa1K7T_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "print(lemmatizer.lemmatize(\"running\", pos='v'))  # Resultado: run\n"
      ],
      "metadata": {
        "id": "t2FeInMgK9FA"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}